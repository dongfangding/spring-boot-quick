# redis单机
redis_host: 127.0_0.1
redis_port: 9999
redis_password: password
# redis集群
redis_node: localhost:6371,localhost:6372,localhost:6373,localhost:6374,localhost:6375,localhost:6376

# zookeeper地址,host:port, 多个用,隔开
zk_addr: localhost:2181,localhost:2182,localhost:2183

# mysql
mysql_host: localhost
mysql_port: 9999
mysql_db: boot-quick
mysql_username: username
mysql_password: password

# rabbitmq相关
rabbit_address: localhost:5672
rabbit_username: username
rabbit_password: password


# rocket name-server地址
rocketmq_name_server: localhost:9876

# mongo
mongodb_url: mongodb://user:pass@localhost:port/boot-quick?authSource=admin

# xxl-job
xxl_admin_addresses: http://127.0.0.1:8805

spring:
  datasource:
    initialization-mode: ALWAYS
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      driver-class-name: com.p6spy.engine.spy.P6SpyDriver  # 优化sql显示插件，对性能有一定影响
      url: jdbc:p6spy:mysql://${mysql_host}:${mysql_port}/${mysql_db}?useUnicode=true&characterEncoding=UTF8&useSSL=false&serverTimezone=GMT%2B8&zeroDateTimeBehavior=convertToNull&allowMultiQueries=true&autoReconnect=true&failOverReadOnly=false&maxReconnects=10&tinyInt1isBit=false
      username: ${mysql_username}
      password: ${mysql_password} # https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter可以配置生数据库加密
      initial-size: 5
      asyncInit: true
      max-active: 30
      min-idle: 10
      keep-alive: true
      max-wait: 60000
      use-unfair-lock: true
      # 回收连接相关
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 600000
      validation-query: SELECT 1
      test-while-idle: true
      test-on-borrow: true
      test-on-return: false
      poolPreparedStatements: false
      max-open-prepared-statements: 20
      filter:
        stat:
          enabled: true
          log-slow-sql: true
          slow-sql-millis: 3000
        wall:
          enabled: true # 开启WallFilter
          db-type: mysql
      ## 开启内置监控界面 访问路径: /context-path/druid/index.html
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
        reset-enable: true
        login-username: admin
        login-password: 123456
        allow:

  # 国际化资源文件
  messages:
    basename: exception/exception
    use-code-as-default-message: false

  redis:
    cluster:
      max-redirects: 3
      nodes: ${redis_node}
    password: ${redis_password}
    database: 0
    jedis:
      pool:
        max-active: 100
        max-idle: 10
        min-idle: 0
        max-wait: 800ms
    timeout: 1000ms
#  redis:
#    database: 0
#    jedis:
#      pool:
#        max-active: 100
#        max-idle: 10
#        min-idle: 0
#        max-wait: 800ms
#    timeout: 1000ms
#    host: ${redis_host}
#    port: ${redis_port}
#    password: ${redis_password}

  mail:
    username: 1041765757@qq.com                # 用来验证授权的邮件用户名
    password: gotartrfwuytbcji                # 根据QQ邮箱设置-账户里生成的第三方登陆授权码，可用来代替密码登陆
    host: smtp.qq.com                         # 邮件服务器类型
    properties.mail.smtp.ssl.enable: true # 用以支持授权码登陆

  rabbitmq:
    addresses: ${rabbit_address}
    username: ${rabbit_username}
    password: ${rabbit_password}
    virtualHost: /
    cache:
      channel:
        size: 100
        checkoutTimeout: 3000
      connection:
        mode: connection
        size:
    template:
      retry:
        enabled: true
        maxAttempts: 5
        initialInterval: 2000  # 第一次和第二次尝试传递消息之间的持续时间
  data:
    mongodb:
      uri: ${mongodb_url}

  websocket:
    properties:
      handshakeTokenSecret: true
      ignoreAuthTimestamp: true # websocket连接时忽略时间戳校验
      messageSecret: false

#  rabbitmq:
#    addresses: localhost:5672
#    username: root
#    password: password
#    virtual-host: / # 创建的虚拟主机，可以简单理解为一个实例，所有队列交换器路由等都是在它的基础上，默认为/，最好自己新建一个
#    publisher-confirms: true # 消息被投递之后如何确保一定被正确投递或消费，开启conform模式
#    listener:
#      direct:
#        acknowledge-mode: manual  # 开启手动ack
#      simple:
#        acknowledge-mode: manual # 开启手动ack
#        retry:
#          enabled: false
#          max-attempts: 3
#          initial-interval: 3000 # 第一次和第二次尝试传递消息之间的持续时间
#        default-requeue-rejected: false

rocketmq:
  name-server: ${rocketmq_name_server}
  producer:
    group: boot-quick-producer-group
    send-message-timeout: 10000
    retryNextServer: true

distributed:
  lock:
    zookeeper:
      root: /distributed_lock
      connectString: ${zk_addr}

elasticjob:
  reg-center:
    server-lists: ${zk_addr}
  tracing:
    type: RDB # 事件追踪配置,需要配合数据库数据源
  dump:
    port: 9999
  jobs:
    # https://shardingsphere.apache.org/elasticjob/current/cn/user-manual/elasticjob-lite/configuration/
    timeReportJob:
      # https://shardingsphere.apache.org/elasticjob/current/cn/faq/#3-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9C%A8%E4%BB%A3%E7%A0%81%E6%88%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E4%BF%AE%E6%94%B9%E4%BA%86%E4%BD%9C%E4%B8%9A%E9%85%8D%E7%BD%AE%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E9%85%8D%E7%BD%AE%E5%8D%B4%E6%B2%A1%E6%9C%89%E6%9B%B4%E6%96%B0
      # 本地配置是否可覆盖注册中心配置
      overwrite: true
      jobParameter: 我是从配置文件传过来的一个jobParameter
      # 每次作业执行时间和间隔时间均非常短的情况，建议不监控作业运行时状态以提升效率。 因为是瞬时状态，所以无必要监控。请用户自行增加数据堆积监控。
      # 并且不能保证数据重复选取，应在作业中实现幂等性。 每次作业执行时间和间隔时间均较长的情况，建议监控作业运行时状态，可保证数据不会重复选取
      monitorExecution: true
      # 任务开发的bean class
      elasticJobClass: com.ddf.boot.quick.elasticjob.TimeReportJob
      cron: 0 0/5 * * * ?
      # 分片总数， 分片总数如果大于1将会尽量平均分配给多个服务节点（如果存在），然后任务触发的时候多个节点都会执行代码，但如果自己的任务
      # 只希望同一时刻只有一个节点执行，则要配置为1.否则就是类似于多个服务节点平均分配分片然后来瓜分任务的意思，可以理解为fork-join框架的思想
      # 所以分片数如果大于1，一定是为了利用服务器的资源然后各自执行不同数据段的代码，这样分片才有意义
      shardingTotalCount: 1
      # 个性化分片参数 加入需要分片执行的话，给每个分片传递参数，以便进行数据业务切分隔离，互不影响
      shardingItemParameters: 0=Beijing,1=Shanghai,2=Guangzhou
      # 当作业执行过程中服务器宕机，失效转移允许将该次未完成的任务在另一作业节点上补偿执行。失效转移需要与监听作业运行时状态同时开启才可生效。
      # 开启失效转移功能，ElasticJob 会监控作业每一分片的执行状态，并将其写入注册中心，供其他节点感知。
      # 在一次运行耗时较长且间隔较长的作业场景，失效转移是提升作业运行实时性的有效手段； 对于间隔较短的作业，会产生大量与注册中心的网络通信，
      # 对集群的性能产生影响。 而且间隔较短的作业并未见得关注单次作业的实时性，可以通过下次作业执行的重分片使所有的分片正确执行，因此不建议短间隔作业开启失效转移。
      failover: false
      # ElasticJob 不允许作业在同一时间内叠加执行。 当作业的执行时长超过其运行间隔，错过任务重执行能够保证作业在完成上次的任务后继续执行逾期的作业。
      # 在一次运行耗时较长且间隔较长的作业场景，错过任务重执行是提升作业运行实时性的有效手段； 对于未见得关注单次作业的实时性的短间隔的作业来说，开启错过任务重执行并无必要。
      misfire: false

xxl-job:
  adminAddresses: ${xxl_admin_addresses}
  accessToken: xxl_develop # 访问token, 需要和xxl-job-admin里的配置一致
  appName: auto # 以spring.application.name
  port: 0 # 自动获取
  logPath: /opt/services/xxl-job/logs/jobhandler # 日志目录
  logRetentionDays: 14 # 日志保留天数

customs:  # 自定义的属性最好都写在custom前缀下，方便辨认
  global-properties:
    snowflakeWorkerId: 1      # worker Id can't be greater than 31 or less than 0
    snowflakeDataCenterId: 1  # dataCenterId Id can't be greater than 31 or less than 0
    ignoreErrorTraceProfile:  # 过滤将异常堆栈信息输出打前端接口返回值的环境
      - pre
      - prod
    exception200: true  # 异常模式， true标识使用异常时保证http状态码为200，使用返回数据标识具体异常
  message_secret: false # 是否加密传输websocket消息数据

  zookeeper:
    monitor:
      connectAddress: ${zk_addr}

  ext:
    ## oss服务配置 com.ddf.boot.common.ext.oss.config.OssProperties
    oss:
      endpoint: oss-cn-shanghai.aliyuncs.com
      accessKeyId: d86b0b8b1c525ee7c4ab54592902baee0fdbba93e20bff5a1016608b9c41053c
      accessKeySecret: 57a8e5c1c3280f3e72c754f4b5a2e326e663ca94414f7ec13a67c2fafd9886ff
      secret: true
      stsEndpoint: sts.cn-shanghai.aliyuncs.com
      roleArn: acs:ram::1863283291831992:role/ramosssts
      roleSessionName: boot-quick
      durationSeconds: 1800
      buckets:
        - bucketName: ddf-private
          bucketEndpoint: ddf-private.oss-cn-shanghai.aliyuncs.com
          primary: true
    ## 短信服务配置 com.ddf.boot.common.ext.sms.config.SmsProperties
    sms:
      endpoint: dysmsapi.aliyuncs.com
      protocol: HTTP
      secretAccessKey: true
      accessKeyId: d86b0b8b1c525ee7c4ab54592902baee0fdbba93e20bff5a1016608b9c41053c
      accessKeySecret: 57a8e5c1c3280f3e72c754f4b5a2e326e663ca94414f7ec13a67c2fafd9886ff
      sinaName: ABC商城
      templateCode: SMS_204455240
      useRandomCode: true


  jwt:
    secret: WoshiyigefenshuajiangfenshuabenlingqiangwoyaobanaxinfangzishuadegengpiaoliangshualefangziyoushuangqiangaiyawodexiaobizibianyabianleYang
    expiredMinute: 1080  # jwt token过期时间，单位分钟
    refreshTokenMinute: 10  # 在jwt token有效时间剩余达到了这个时间（分钟），如果用户在线（即调用了任意接口）则服务端主动刷新用户token并返回，需要前端配合处理重新替换用户token
    ignores:  ## 接口用户认证请求拦截忽略路径
      - path: /quick-start/**
      - path: /v2/*
      - path: /swagger-ui.html
      - path: /swagger-ui.html/*
      - path: /swagger-resources/**
      - path: /swagger/**
      - path: /webjars/**
      - path: /druid/**
      - path: /csrf
      - path: /app.js
      - path: /websocket.html
      - path: /websocket.html
      - path: /js/*
      - path: /ws/*
      - path: /pay-ws/*
      - path: /heartCheck.txt
      - path: /authUser/registry
      - path: /authUser/loginByPassword
      - path: /index.html
      - path: /favicon.ico
  rsa:
    primaryKey: MIICdgIBADANBgkqhkiG9w0BAQEFAASCAmAwggJcAgEAAoGBAIPT0VbUrdYMIX//tgHgaMh9PUtqG6R/lNOvIl9LR6Mbc5J03qjvLlu2IifHFbFonm6XguZG4LZ4H3hRkX9fC4qSaQR1vZBOvS1aNLRyvMZudISJygiag1qJOQMEwrb8JUZkP7NMpBNjYpmF344+25Il3axRnd1oVR4Hhp4tqEe1AgMBAAECgYBYv0i3BAbjitcirKuDJ+hi0K1rD8v8OkefGtAxByT7EYgEmNktMZgr9bmYvdZE0QGXwjhFfoHZVZUaEw+4h+vkJrXxv2FQHqTSL8fDeL4jggNO3YYpLFoq9bvwWeqDJ3vvVkJEbNycfoE6iXv91mUM3hb7ie1NlvWYOJtiAxf0AQJBAOzyLcea/8Au8nVnJrVstpVaItkib7pT/9w2BDAe821JTXsmUCGw47LpYHZos6G8pR9Hz8VRaj99z8Z5xa2fe2ECQQCObaUe0n67ddr3OExVF9LyFVEdGzvuOwJjQi6/URvhrQDV31kld2z9lqV6p2l6JpDpmQIwPsJTS7qbLLhjGqDVAkEAz+Gh3I/Wdiw6OFqpkV6xydLs5AfccmMkBXW2sulUtLstKTBx+T0SaHNsWDZ/8xRo4krEtN87Ej01P3KyxiM3wQJAaJirF5ycR40AtmeY3zD00KXJAOgcNhMN6NkUvZmSMUS9BVPWAwbWetEkS5QgiP1DlNmyWr3sNgG6U/UeoGFQ1QJAZief8zE0C5jCmWf7VwfAJCSd+r+BVcSCpUxskc3gnhfG6j+ImAirhXIY+ld8rArmGl4UPkQfapBphUJslWLpLg==
    publicKey: MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCD09FW1K3WDCF//7YB4GjIfT1Lahukf5TTryJfS0ejG3OSdN6o7y5btiInxxWxaJ5ul4LmRuC2eB94UZF/XwuKkmkEdb2QTr0tWjS0crzGbnSEicoImoNaiTkDBMK2/CVGZD+zTKQTY2KZhd+OPtuSJd2sUZ3daFUeB4aeLahHtQIDAQAB


leaf:
  name: com.sankuai.leaf.opensource.snowflake
  segment:
    enable: false
  snowflake:
    enable: true
    address: ${zk_addr}


logging:
  level:
    root: info
    com.ddf.boot.common.log.AccessLogAspect: debug
    #    com.ddf.boot.quick.mapper: debug   因为用了sql插件，这里可以先注释掉
    com.ddf.boot.common.mq: debug
    com.ddf.boot.netty.broker: debug

